{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA GPU!\n"
     ]
    }
   ],
   "source": [
    "import dense_correspondence_manipulation.utils.utils as utils\n",
    "utils.add_dense_correspondence_to_python_path()\n",
    "import dense_correspondence\n",
    "reload(dense_correspondence)\n",
    "from dense_correspondence.training.training import *\n",
    "import sys\n",
    "import logging\n",
    "import json\n",
    "import time\n",
    "\n",
    "#utils.set_default_cuda_visible_devices()\n",
    "# utils.set_cuda_visible_devices([0]) # use this to manually set CUDA_VISIBLE_DEVICES\n",
    "\n",
    "import dense_correspondence.dataset.spartan_dataset_masked\n",
    "reload(dense_correspondence.dataset.spartan_dataset_masked)\n",
    "import dense_correspondence.training.training\n",
    "reload(dense_correspondence.training.training)\n",
    "from dense_correspondence.training.training import DenseCorrespondenceTraining\n",
    "from dense_correspondence.dataset.spartan_dataset_masked import SpartanDataset, OPDataSelector\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import dense_correspondence.evaluation.evaluation\n",
    "reload(dense_correspondence.evaluation.evaluation)\n",
    "from dense_correspondence.evaluation.evaluation import DenseCorrespondenceEvaluation\n",
    "\n",
    "# Multi Object Pursuit\n",
    "utils.add_object_pursuit_to_python_path()\n",
    "import object_pursuit\n",
    "reload(object_pursuit)\n",
    "from dense_correspondence.training.op_training import OPDenseCorrespondenceTraining\n",
    "\n",
    "from dense_correspondence.network.op_dense_correspondence_network import \\\n",
    "    OPMultiDenseCorrespondenceNetwork, OPMultiDenseCorrespondenceNetworkV2\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "DEVICE = \"cuda:1\" if cuda else \"cpu\"\n",
    "if cuda:\n",
    "    print(\"CUDA GPU!\")\n",
    "else:\n",
    "    print(\"CPU!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the configuration for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "verbose = False\n",
    "config_filename = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', 'dense_correspondence', \n",
    "                               'dataset', 'composite', 'op_pretraining.yaml')\n",
    "data_config = utils.getDictFromYamlFilename(config_filename)\n",
    "data_config['logs_root_path'] = '/home/ashek/code/data/pdc/logs_proto'\n",
    "\n",
    "# Training\n",
    "train_config_file = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', 'dense_correspondence', \n",
    "                               'training', 'op_pretraining.yaml')\n",
    "train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "train_config['device'] = DEVICE\n",
    "train_config['dense_correspondence_network']['device'] = DEVICE\n",
    "\n",
    "logging_dir = \"/home/ashek/code/data/pdc/trained_models/tutorials\"\n",
    "num_iterations = 3500\n",
    "d = 3 # the descriptor dimension\n",
    "datetime_str = time.strftime('%Y_%m_%d_%H:%M:%S', time.localtime())\n",
    "name = \"op_multinet_pretraining_\" + datetime_str\n",
    "train_config[\"training\"][\"logging_dir_name\"] = name\n",
    "train_config[\"training\"][\"logging_dir\"] = logging_dir\n",
    "train_config[\"dense_correspondence_network\"][\"descriptor_dimension\"] = d\n",
    "train_config[\"training\"][\"num_iterations\"] = num_iterations\n",
    "print(json.dumps(train_config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network\n",
    "\n",
    "This should take about ~12-15 minutes with a GTX 1080 Ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.get_pose_data(dataset.get_scene_list()[0])\n",
    "data_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# All of the saved data for this network will be located in the\n",
    "# code/data/pdc/trained_models/tutorials/caterpillar_3 folder\n",
    "print(train_config.keys())\n",
    "print \"training descriptor of dimension %d\" %(d)\n",
    "NetworkClass = OPMultiDenseCorrespondenceNetworkV2\n",
    "# NetworkClass = OPMultiDenseCorrespondenceNetwork\n",
    "train_config[\"dense_correspondence_network\"][\"model_class\"] = str(NetworkClass)\n",
    "train = OPMultiDenseCorrespondenceTraining(NetworkClass=NetworkClass, config=train_config)\n",
    "train.load_dataset_from_config(config=data_config)\n",
    "train.run()\n",
    "print \"finished training descriptor of dimension %d\" %(d)\n",
    "\n",
    "# Each batch, select a random image from a random scene\n",
    "# for that image, find another image from the same scene\n",
    "# but a taken from a diff view.\n",
    "# then generate both pixel matches and non-matches \n",
    "# yes there is a heuristic approach, but it seeems complex\n",
    "# and thus runtime is long. Prune non-matches based on:\n",
    "# 1. depth is 0 (thus invalid, cannot use)\n",
    "# 2. Project pixels from im1 to onto im2 and check if outside FOV\n",
    "# 3. check if pixel is occluded using some method\n",
    "# complicated... don't touch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune on New Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New objects\n",
    "# Datasets available:\n",
    "# caterpillar_upright\n",
    "# mugs\n",
    "# shoes\n",
    "# drills\n",
    "config_filename = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', 'dense_correspondence', \n",
    "                               'dataset', 'composite', 'finetune.yaml')\n",
    "finetune_config = utils.getDictFromYamlFilename(config_filename)\n",
    "finetune_config['logs_root_path'] = '/home/ashek/code/data/pdc/logs_proto'\n",
    "finetune_dataset = SpartanDataset(config=finetune_config)\n",
    "print(json.dumps(finetune_config, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 1500\n",
    "d = 3 # the descriptor dimension\n",
    "train_config[\"training\"][\"num_iterations\"] = num_iterations\n",
    "print(json.dumps(train_config, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = os.path.join(logging_dir, name)\n",
    "model_folder = utils.convert_data_relative_path_to_absolute_path(model_folder)\n",
    "print(\"Loading %s\" % model_folder)\n",
    "iteration = 3501\n",
    "print \"training descriptor of dimension %d\" %(d)\n",
    "finetune = DenseCorrespondenceTraining(dataset=finetune_dataset, config=train_config)\n",
    "finetune.run_from_pretrained(model_folder, iteration)\n",
    "print \"finished training descriptor of dimension %d\" %(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/ashek/code/data/pdc/trained_models/tutorials/caterpillar_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the network quantitatively\n",
    "\n",
    "This should take ~5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate initial model (no fine-tuning) on original train dataset\n",
    "DCE = DenseCorrespondenceEvaluation\n",
    "iteration = 3501\n",
    "num_image_pairs = 100\n",
    "save_folder_name = \"analysis\"\n",
    "DCE.run_evaluation_on_network(model_folder, iteration=iteration, num_image_pairs=num_image_pairs,\n",
    "                             dataset=dataset, save_folder_name=save_folder_name)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate fine-tuned model on original train dataset\n",
    "iteration = 5002\n",
    "num_image_pairs = 100\n",
    "save_folder_name = \"finetune_analysis_orig_data\"\n",
    "DCE.run_evaluation_on_network(model_folder, iteration=iteration, num_image_pairs=num_image_pairs,\n",
    "                             dataset=dataset, save_folder_name=save_folder_name)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate fine-tuned model on new finetuned dataset\n",
    "DCE = DenseCorrespondenceEvaluation\n",
    "iteration = 5002\n",
    "num_image_pairs = 100\n",
    "save_folder_name = \"finetune_analysis_finetune_data\"\n",
    "DCE.run_evaluation_on_network(model_folder, iteration=iteration, num_image_pairs=num_image_pairs,\n",
    "                             dataset=finetune_dataset, save_folder_name=save_folder_name)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `evaluation_quantitative_tutorial.ipynb` for a better place to display the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune on 2nd additional dataset just to emphasize issue further\n",
    "config_filename = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', 'dense_correspondence', \n",
    "                               'dataset', 'composite', 'finetune2.yaml')\n",
    "finetune2_config = utils.getDictFromYamlFilename(config_filename)\n",
    "finetune2_config['logs_root_path'] = '/home/ashek/code/data/pdc/logs_proto'\n",
    "finetune2_dataset = SpartanDataset(config=finetune_config)\n",
    "print(json.dumps(finetune2_config, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = os.path.join(logging_dir, name)\n",
    "model_folder = utils.convert_data_relative_path_to_absolute_path(model_folder)\n",
    "print(\"Loading %s\" % model_folder)\n",
    "iteration = 5002\n",
    "print \"training descriptor of dimension %d\" %(d)\n",
    "finetune2 = DenseCorrespondenceTraining(dataset=finetune2_dataset, config=train_config)\n",
    "finetune2.run_from_pretrained(model_folder, iteration)\n",
    "print \"finished training descriptor of dimension %d\" %(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate fine-tuned2 model on new finetuned2 dataset\n",
    "DCE = DenseCorrespondenceEvaluation\n",
    "iteration = 6503\n",
    "num_image_pairs = 100\n",
    "save_folder_name = \"finetune2_analysis_finetune_data2\"\n",
    "DCE.run_evaluation_on_network(model_folder, iteration=iteration, num_image_pairs=num_image_pairs,\n",
    "                             dataset=finetune2_dataset, save_folder_name=save_folder_name)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate fine-tuned model on original train dataset\n",
    "iteration = 6503\n",
    "num_image_pairs = 100\n",
    "save_folder_name = \"finetune2_analysis_orig_data\"\n",
    "DCE.run_evaluation_on_network(model_folder, iteration=iteration, num_image_pairs=num_image_pairs,\n",
    "                             dataset=dataset, save_folder_name=save_folder_name)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
